
# Proyecto de NLP

Este proyecto se enfoca en el **Procesamiento de Lenguaje Natural (NLP)** utilizando tÃ©cnicas avanzadas de **machine learning** y **deep learning** para tareas como anÃ¡lisis de sentimiento, clasificaciÃ³n de texto, y generaciÃ³n de lenguaje. Usamos herramientas como `nltk`, `spacy` y `transformers`.

## Estructura del Proyecto

```plaintext
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Datos crudos
â”‚   â”œâ”€â”€ processed/         # Datos procesados listos para modelado
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploracion.ipynb  # ExploraciÃ³n y visualizaciÃ³n de datos
â”‚   â”œâ”€â”€ model_training.ipynb # Entrenamiento y evaluaciÃ³n de modelos
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py   # CÃ³digo de preprocesamiento de texto
â”‚   â”œâ”€â”€ models.py          # DefiniciÃ³n de modelos de NLP
â”‚   â””â”€â”€ utils.py           # Funciones auxiliares
â”œâ”€â”€ main.py                # Script principal del proyecto
â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â””â”€â”€ README.md              # DescripciÃ³n del proyecto
```

## Objetivos del Proyecto

- **Preprocesamiento de texto:** Limpieza, tokenizaciÃ³n, lematizaciÃ³n y eliminaciÃ³n de stopwords.
- **Modelos de clasificaciÃ³n:** Entrenar modelos supervisados como Naive Bayes, SVM y transformers para la clasificaciÃ³n de texto.
- **GeneraciÃ³n de texto:** Implementar modelos avanzados como GPT para la creaciÃ³n automÃ¡tica de texto coherente.
- **EvaluaciÃ³n de modelos:** Medir el rendimiento con mÃ©tricas como accuracy, precision, recall y F1 score.

## InstalaciÃ³n

Para ejecutar este proyecto, clona el repositorio y luego instala las dependencias usando `pip`:

```bash
git clone https://github.com/tu-usuario/NLP_Projecto.git
cd NLP_Projecto
pip install -r requirements.txt
```

### Dependencias clave:
- **nltk:** Procesamiento de lenguaje natural.
- **spacy:** TokenizaciÃ³n avanzada y lematizaciÃ³n.
- **transformers:** Modelos avanzados como BERT y GPT.
- **scikit-learn:** Algoritmos clÃ¡sicos de machine learning.
- **pandas y numpy:** ManipulaciÃ³n de datos y operaciones numÃ©ricas.

## âš™ï¸ Uso del Proyecto

### 1. Preprocesamiento de Datos

Limpia y transforma los datos utilizando el script `preprocessing.py`:

```bash
python src/preprocessing.py --input data/raw/dataset.csv --output data/processed/cleaned_data.csv
```

### 2. Entrenamiento de Modelos

Entrena un modelo de clasificaciÃ³n o generaciÃ³n de texto usando los notebooks o ejecutando el script principal:

```bash
python main.py --train --model svm --input data/processed/cleaned_data.csv
```

### 3. EvaluaciÃ³n del Modelo

EvalÃºa el rendimiento del modelo con este comando:

```bash
python main.py --evaluate --model svm --input data/processed/cleaned_data.csv
```

### 4. GeneraciÃ³n de Texto

Genera texto usando un modelo como GPT:

```bash
python main.py --generate --model gpt --input "Completa esta frase:"
```

## ğŸ“Š Notebooks

Los notebooks incluidos en el proyecto, que puedes ejecutar localmente o en Google Colab, son:

- `exploracion.ipynb`: AnÃ¡lisis exploratorio de los datos.
- `model_training.ipynb`: Entrenamiento y evaluaciÃ³n de modelos NLP.

## ğŸ”§ ConfiguraciÃ³n de Entrenamiento

Al ejecutar el script `main.py`, puedes especificar el tipo de modelo y el dataset a utilizar. Por ejemplo, para entrenar un modelo SVM:

```bash
python main.py --train --model svm --input data/processed/cleaned_data.csv
```

O para usar un modelo basado en transformers como BERT:

```bash
python main.py --train --model bert --input data/processed/cleaned_data.csv
```

## ğŸ” EvaluaciÃ³n de Resultados

Las mÃ©tricas de evaluaciÃ³n y grÃ¡ficos de rendimiento se almacenan automÃ¡ticamente en la carpeta `results/`. Incluyen:

- Matrices de confusiÃ³n.
- Reportes de clasificaciÃ³n.
- ComparaciÃ³n de rendimiento entre modelos.

## Contribuciones

Si deseas contribuir a este proyecto:

1. Haz un fork del repositorio.
2. Crea una nueva rama (`git checkout -b feature/nueva-funcionalidad`).
3. Realiza tus cambios y haz un commit (`git commit -m 'Agregar nueva funcionalidad'`).
4. Sube tus cambios (`git push origin feature/nueva-funcionalidad`).
5. Abre un pull request.

## Futuras Mejoras

- Implementar **transfer learning** utilizando modelos preentrenados como BERT y GPT.
- AÃ±adir funciones de **resÃºmenes automÃ¡ticos** y tÃ©cnicas avanzadas de **traducciÃ³n automÃ¡tica**.
- OptimizaciÃ³n y ajuste de hiperparÃ¡metros usando **GridSearch** o **Bayesian Optimization**.
